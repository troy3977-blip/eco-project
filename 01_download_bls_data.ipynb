import pandas as pd
from pathlib import Path

# Adjust these paths/names to match where you put the downloads
DATA_RAW = Path("C:\Users\troym\OneDrive\data_raw") / "data_raw"

# Example: unemployment, nonfarm employment, and labor force participation
unemp = pd.read_csv(DATA_RAW / "unemployment_rate.csv")
nonfarm = pd.read_csv(DATA_RAW / "nonfarm_payrolls.csv")
lfp = pd.read_csv(DATA_RAW / "labor_force_participation.csv")

# Make sure each has a proper datetime column named "date"
# (You may need to tweak these lines based on your actual column names)
for df in [unemp, nonfarm, lfp]:
    df["date"] = pd.to_datetime(df["date"])  # or "DATE" / "Year"/"Month" etc.
    df.set_index("date", inplace=True)

# Rename value columns so they don't collide
unemp = unemp.rename(columns={"value": "unemployment_rate"})
nonfarm = nonfarm.rename(columns={"value": "nonfarm_employment_thousands"})
lfp = lfp.rename(columns={"value": "labor_force_participation"})

# Combine them on the date index
df_labor = unemp[["unemployment_rate"]]\
    .join(nonfarm[["nonfarm_employment_thousands"]], how="inner")\
    .join(lfp[["labor_force_participation"]], how="inner")

df_labor.head()

import io
import requests

# If you haven't downloaded USREC yet:
usrec_url = "https://fred.stlouisfed.org/graph/fredgraph.csv?id=USREC"
resp = requests.get(usrec_url)
resp.raise_for_status()
df_rec = pd.read_csv(io.StringIO(resp.text))

df_rec["date"] = pd.to_datetime(df_rec["DATE"])
df_rec = df_rec.rename(columns={"USREC": "recession_now"})
df_rec = df_rec.set_index("date")

# Join onto the labor data
df = df_labor.join(df_rec["recession_now"], how="inner")
df.head()

OUTPUT_DIR = Path("..") / "data_curated"
OUTPUT_DIR.mkdir(exist_ok=True)

df.to_csv(OUTPUT_DIR / "labor_recession_raw.csv")
len(df), df.head()

